<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Inference for Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Stat 20 UC Berkeley, Fall 2021" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <link href="libs/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="libs/countdown-0.3.5/countdown.js"></script>
    <link rel="stylesheet" href="stat20-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Inference for Regression
### Stat 20 UC Berkeley, Fall 2021

---




class: center, middle
.adage[Some chatter from the internets]

--

## 2016 Election

&lt;img src="figs/538.png" width="700" style="display: block; margin: auto;" /&gt;

--

**Question at hand**: How will Obama's 46% approval rating effect his
party's candidate for the 2016 presidential election?


---

&lt;img src="figs/538-1.png" width="700" style="display: block; margin: auto;" /&gt;


---

&lt;img src="figs/538-2.png" width="700" style="display: block; margin: auto;" /&gt;

--

.task[
1. Sketch the data frame that Harry is talking about.

2. Sketch a plot of the trend he is describing.

You will have 2 minutes to work solo/silently, then 1 minute to discuss.
]
--

<div class="countdown" id="timer_618efd30" style="right:0;bottom:0;" data-warnwhen="20">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---

&lt;img src="figs/538-3.png" width="700" style="display: block; margin: auto;" /&gt;

--

&gt; Why is it ridiculous?

---
## Inference for Regression
--

We can fit a line through any cloud of points that we please, but if we
just have a *sample* of data, any trend we detect doesn't necessarily 
demonstrate that the trend exists in the *population* at large.


---
## Plato's Allegory of the Cave
--

&lt;img src="figs/plato-cave.jpg" width="850" style="display: block; margin: auto;" /&gt;


---
## Statistical Inference
--

**Goal**: use *statistics* calculated from data to makes inferences about the 
nature of *parameters*.

--

In regression,

- parameters: `\(\beta_0\)`, `\(\beta_1\)`
- statistics: `\(b_0\)`, `\(b_1\)`

Classical tools of inference:

- Confidence Intervals
- Hypothesis Tests

---
## Unemployment and elections
--




```r
ump
```

--


```
## # A tibble: 29 Ã— 5
##     year potus                     party      unemp change
##    &lt;dbl&gt; &lt;chr&gt;                     &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt;
##  1  1899 William McKinley          Republican 11.6   -9.22
##  2  1903 Theodore Roosevelt        Republican  4.3   -4.28
##  3  1907 Theodore Roosevelt        Republican  3.29 -12.3 
##  4  1911 William Howard Taft       Republican  5.86 -26.6 
##  5  1915 Woodrow Wilson            Democratic  6.63 -21.0 
##  6  1919 Woodrow Wilson            Democratic  3.38 -10.3 
##  7  1923 Calvin Coolidge           Republican  6.93 -25.5 
##  8  1927 Calvin Coolidge           Republican  4.02  -3.64
##  9  1931 Herbert Clark Hoover      Republican  8.94 -19.3 
## 10  1935 Franklin Delano Roosevelt Democratic 21.3    2.88
## # â€¦ with 19 more rows
```


---
## Unemployment and elections, cont.
--

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-9-1.png" width="648" style="display: block; margin: auto;" /&gt;

--

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.


---
## Unemployment and elections, cont.

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-10-1.png" width="648" style="display: block; margin: auto;" /&gt;

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.

---
## Unemployment and elections, cont.

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-11-1.png" width="648" style="display: block; margin: auto;" /&gt;

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.


---
## Unemployment and elections, cont.
--

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-12-1.png" width="648" style="display: block; margin: auto;" /&gt;

--

Focusing only on non-Great Depression elections, some evidence of a negative linear relationship between unemployment level and change in party support.
&gt; _or is there?_


---
## H-test for Regression
--

`\(H_0:\)` There is no relationship between unemployment level and change in 
party support (or: change in party support is independent of unemployment).

`\(H_0: \beta_1 = 0\)`

--

### Method
If there is no relationship, the pairing between `\(X\)` and `\(Y\)` is
artificial and we can permute:

1. Generate synthetic data sets under `\(H_0\)` by shuffling `\(X\)`.
2. Compute a new regression line for each data set and store each `\(b_1\)`.
3. See where your observed `\(b_1\)` falls in the distribution of `\(b_1\)`'s under `\(H_0\)`.


---
## Your turn

.task[
Take a moment to sketch out the infer pipeline that will results in a collection of 500 slopes that would might see in a world where the null hypothesis was true.

Turn to a neighbor and discuss your pipeline. I will ask for a pair to share.
]

--


```r
ump
```

```
## # A tibble: 27 Ã— 5
##     year potus                     party      unemp change
##    &lt;dbl&gt; &lt;chr&gt;                     &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt;
##  1  1899 William McKinley          Republican 11.6   -9.22
##  2  1903 Theodore Roosevelt        Republican  4.3   -4.28
##  3  1907 Theodore Roosevelt        Republican  3.29 -12.3 
##  4  1911 William Howard Taft       Republican  5.86 -26.6 
##  5  1915 Woodrow Wilson            Democratic  6.63 -21.0 
##  6  1919 Woodrow Wilson            Democratic  3.38 -10.3 
##  7  1923 Calvin Coolidge           Republican  6.93 -25.5 
##  8  1927 Calvin Coolidge           Republican  4.02  -3.64
##  9  1931 Herbert Clark Hoover      Republican  8.94 -19.3 
## 10  1943 Franklin Delano Roosevelt Democratic  4.7  -16.9 
## # â€¦ with 17 more rows
```


<div class="countdown" id="timer_618efdec" style="right:0;bottom:0;" data-warnwhen="20">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---

Take a moment to sketch out the infer pipeline that will results in a collection of 500 slopes that would might see in a world where the null hypothesis was true.


```r
null &lt;- ump %&gt;%
  specify(change ~ unemp) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 500, type = "permute") %&gt;%
  calculate(stat = "slope")
```


---
## First shuffle
--

.pull-left[

```r
library(infer)
ump %&gt;%
  specify(change ~ unemp) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(1, type = "permute")
```
]

---
## First shuffle

.pull-left[

```r
library(infer)
ump %&gt;%
  specify(change ~ unemp) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(1, type = "permute")
```


```
## Response: change (numeric)
## Explanatory: unemp (numeric)
## Null Hypothesis: independence
## # A tibble: 27 Ã— 3
## # Groups:   replicate [1]
##    change unemp replicate
##     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;
##  1 -19.3  11.6          1
##  2 -10.3   4.3          1
##  3 -24.9   3.29         1
##  4  -5.14  5.86         1
##  5  -8.14  6.63         1
##  6  -4.57  3.38         1
##  7   2.43  6.93         1
##  8 -26.6   4.02         1
##  9  -6.25  8.94         1
## 10 -12.9   4.7          1
## # â€¦ with 17 more rows
```
]

---
## Second shuffle
--

.pull-left[

```r
library(infer)
ump %&gt;%
  specify(change ~ unemp) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(1, type = "permute")
```

```
## Response: change (numeric)
## Explanatory: unemp (numeric)
## Null Hypothesis: independence
## # A tibble: 27 Ã— 3
## # Groups:   replicate [1]
##    change unemp replicate
##     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;
##  1 -24.2  11.6          1
##  2  -2.75  4.3          1
##  3  -1.07  3.29         1
##  4  -9.22  5.86         1
##  5 -20.9   6.63         1
##  6  -4.57  3.38         1
##  7 -21.0   6.93         1
##  8  -5.14  4.02         1
##  9 -13.5   8.94         1
## 10   3.62  4.7          1
## # â€¦ with 17 more rows
```
]

.pull-right[

```r
shuffle2 &lt;- ump %&gt;%
  specify(change ~ unemp) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(1, type = "permute")
shuffle2
```

```
## Response: change (numeric)
## Explanatory: unemp (numeric)
## Null Hypothesis: independence
## # A tibble: 27 Ã— 3
## # Groups:   replicate [1]
##    change unemp replicate
##     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;
##  1 -25    11.6          1
##  2   2.43  4.3          1
##  3  -3.64  3.29         1
##  4 -10.3   5.86         1
##  5 -22.3   6.63         1
##  6 -16.3   3.38         1
##  7 -19.3   6.93         1
##  8 -20.9   4.02         1
##  9  -9.22  8.94         1
## 10  -6.25  4.7          1
## # â€¦ with 17 more rows
```
]



---
## Second shuffle, visualized


```r
shuffle2 %&gt;%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Total change of seats in Congress")
```
--
&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-19-1.png" width="648" style="display: block; margin: auto;" /&gt;


---
## Second shuffle, visualized


```r
shuffle2 %&gt;%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Total change of seats in Congress") +
*   stat_smooth(method = "lm", se = FALSE)
```

--

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-20-1.png" width="648" style="display: block; margin: auto;" /&gt;


---
## Third shuffle, visualized
--





```r
*shuffle3 %&gt;%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Total change of seats in Congress") +
    stat_smooth(method = "lm", se = FALSE)
```

--

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-22-1.png" width="648" style="display: block; margin: auto;" /&gt;


---
class: small
## Fourth shuffle, visualized




```r
*shuffle4 %&gt;%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Total change of seats in Congress") +
    stat_smooth(method = "lm", se = FALSE)
```

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-24-1.png" width="648" style="display: block; margin: auto;" /&gt;

---
## Visualize 15 permuted `\(b_1\)`'s





---
## Generate 500 permuted `\(b_1\)`'s
--


```r
null &lt;- ump %&gt;%
  specify(change ~ unemp) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 500, type = "permute") %&gt;%
  calculate(stat = "slope")
null
```

--


```
## Response: change (numeric)
## Explanatory: unemp (numeric)
## Null Hypothesis: independence
## # A tibble: 500 Ã— 2
##    replicate    stat
##        &lt;int&gt;   &lt;dbl&gt;
##  1         1  1.66  
##  2         2  1.20  
##  3         3 -0.177 
##  4         4  0.854 
##  5         5  0.0957
##  6         6 -0.292 
##  7         7  0.949 
##  8         8 -0.597 
##  9         9 -0.799 
## 10        10  0.320 
## # â€¦ with 490 more rows
```

---
## Visualize 500 permuted `\(b_1\)`'s
--



&lt;img src="inference-for-regression_files/figure-html/compute2-1.png" width="648" style="display: block; margin: auto;" /&gt;


---
## Null dist. of `\(b_1\)`
--




```r
null %&gt;%
    visualize() +
    shade_p_value(obs_stat = obs_slope,
                  direction = "both")
```

--

&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-29-1.png" width="648" style="display: block; margin: auto;" /&gt;

--

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.

---
## Null dist. of `\(b_1\)`, cont.
--


```r
null %&gt;%
    get_p_value(obs_stat = obs_slope,
                direction = "both")
```
--

```
## # A tibble: 1 Ã— 1
##   p_value
##     &lt;dbl&gt;
## 1   0.244
```


---
## H-tests for regression
--


```r
m0 &lt;- lm(change ~ unemp, data = ump)
summary(m0)
```

```
## 
## Call:
## lm(formula = change ~ unemp, data = ump)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.0105  -7.8606  -0.1827   7.3890  16.1400 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -6.7142     5.4567  -1.230    0.230
## unemp        -1.0010     0.8717  -1.148    0.262
## 
## Residual standard error: 9.106 on 25 degrees of freedom
## Multiple R-squared:  0.05011,	Adjusted R-squared:  0.01211 
## F-statistic: 1.319 on 1 and 25 DF,  p-value: 0.2617
```


---
## H-tests for regression
--

- Each line in the summary table is a hypothesis test that the parameter is zero.
--

- The summary table from `lm()` will always report p-values associated with a _t test_, regardless of if it's appropriate. ðŸ˜¬
--

- Under certain conditions, the test statistic associated with `\(b\)`'s is distributed 
like `\(t\)` random variables with `\(n - p\)` degrees of freedom.

$$ \frac{b - \beta}{SE} \sim t_{df = n - p}$$


```r
t_stat &lt;- (-1.0010 - 0)/0.8717
pt(t_stat, df = 27 - 2) * 2
```

```
## [1] 0.2617015
```


---
## Conditions for using the `\(t\)` distribution for `\(b_1\)`
--

1. **Linearity**: linear trend between `\(X\)` and `\(Y\)`, check with residual plot.

--

2. **Independent errors**: check with residual plot for serial correlation.

--

3. **Errors with constant variance**: look for constant spread in residual plot.

--

4. **Normally distributed errors**: look at histogram of residuals.

---
## Residuals vs `\(\hat{y}\)`
--

.pull-left[

```r
ump %&gt;%
    mutate(res = residuals(m1),
           yhat = fitted(m1)) %&gt;%
    ggplot(aes(x = yhat,
               y = res)) +
    geom_point() +
    geom_point(size = 3) +
    theme_bw(base_size = 14)
```
]

--

.pull-right[
&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-33-1.png" width="648" style="display: block; margin: auto;" /&gt;
]

--

- Possible non-linear trend
- No sign of serial correlation
- No sign of non-constant variance

---
## Distribution of residuals
--

.pull-left[

```r
ump %&gt;%
    mutate(res = residuals(m1),
           yhat = fitted(m1)) %&gt;%
    ggplot(aes(x = res)) +
    geom_histogram() +
    theme_bw(base_size = 14)
```
]

--

.pull-right[
&lt;img src="inference-for-regression_files/figure-html/unnamed-chunk-34-1.png" width="648" style="display: block; margin: auto;" /&gt;
]

--

- Unlikely to be normal

&gt; So why were the p-values similar?

---
## H-tests for regression
--

- At small sample sizes, p-values and CIs based on the t-distribution require normal errors to be perfectly accurate, but are quite _robust_ to violations of that assumption.

--

- At large sample sizes the normality assumption becomes less important as the Central Limit Theorem takes over (the `\(t\)` converges to the standard normal at large `\(n\)`).

--

- Permutation and bootstrap methods are always an option but they also require reasonable sample sizes to be accurate.

---

&lt;img src="figs/538-3.png" width="700" style="display: block; margin: auto;" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "atelier-forest-light",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
